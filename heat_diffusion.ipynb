{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scorefield.models.ddpm.heat_diffusion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscorefield\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddpm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdenoising_diffusion\u001b[39;00m \u001b[39mimport\u001b[39;00m Unet\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscorefield\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddpm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgaussian_diffusion\u001b[39;00m \u001b[39mimport\u001b[39;00m Diffusion\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscorefield\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddpm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mheat_diffusion\u001b[39;00m \u001b[39mimport\u001b[39;00m HeatDiffusion\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscorefield\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrl_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_config\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscorefield\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     gen_goals, get_url_image, \n\u001b[1;32m     16\u001b[0m     get_url_pretrained, overlay_image, overlay_goal_agent, \n\u001b[1;32m     17\u001b[0m     overlay_images, overlay_goals_agent, log_num_check,\n\u001b[1;32m     18\u001b[0m     get_distance,\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scorefield.models.ddpm.heat_diffusion'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from scorefield.models.ddpm.denoising_diffusion import Unet\n",
    "from scorefield.models.ddpm.gaussian_diffusion import Diffusion\n",
    "from scorefield.models.ddpm.heat_diffusion import HeatDiffusion\n",
    "from scorefield.utils.rl_utils import load_config\n",
    "from scorefield.utils.utils import (\n",
    "    gen_goals, get_url_image, \n",
    "    get_url_pretrained, overlay_image, overlay_goal_agent, \n",
    "    overlay_images, overlay_goals_agent, log_num_check,\n",
    "    get_distance,\n",
    ")\n",
    "from scorefield.utils.diffusion_utils import bilinear_interpolate, bilinear_interpolate_batch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Args\u001b[39;00m\n\u001b[1;32m      2\u001b[0m config_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./scorefield/configs/diffusion.yaml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m args \u001b[39m=\u001b[39m load_config(config_dir)\n\u001b[1;32m      4\u001b[0m device \u001b[39m=\u001b[39m args[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(args[\u001b[39m'\u001b[39m\u001b[39mlog_path\u001b[39m\u001b[39m'\u001b[39m], args[\u001b[39m'\u001b[39m\u001b[39mmodel_path\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Args\n",
    "config_dir = \"./scorefield/configs/diffusion.yaml\"\n",
    "args = load_config(config_dir)\n",
    "device = args['device']\n",
    "\n",
    "model_path = os.path.join(args['log_path'], args['model_path'])\n",
    "\n",
    "# map_img = Image.open(\"map.png\")\n",
    "bg = Image.open('assets/toy_exp/background0.png')\n",
    "wastes = []\n",
    "wastes.append(Image.open('assets/toy_exp/waste0.png'))\n",
    "wastes.append(Image.open('assets/toy_exp/waste4.png'))\n",
    "wastes.append(Image.open('assets/toy_exp/waste5.png'))\n",
    "\n",
    "epochs = args['epochs']\n",
    "batch_size = args['batch_size']\n",
    "goal_num = args['goal_num']\n",
    "goal_bounds = args['goal_bounds']\n",
    "agent_bounds = args['agent_bounds']\n",
    "eval_samples = args['eval_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet2D(Unet):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim, \n",
    "        out_dim, \n",
    "        dim_mults=(1, 2, 4, 8)\n",
    "    ):\n",
    "        super().__init__(dim=dim, out_dim=out_dim, dim_mults=dim_mults)\n",
    "\n",
    "    def forward(self, obs, x_t, t):\n",
    "        score_map = super().forward(obs, t)\n",
    "        score = bilinear_interpolate_batch(score_map, x_t)    # output: (B,2)\n",
    "        return score\n",
    "\n",
    "img_size = args['image_size']\n",
    "noise_steps = args['noise_steps']\n",
    "train_lr = args['train_lr']\n",
    "beta_start = args['beta_start']\n",
    "beta_end = args['beta_end']\n",
    "    \n",
    "model = Unet2D(\n",
    "    dim=img_size,\n",
    "    out_dim = 2,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    ").to(device)\n",
    "\n",
    "diffusion = HeatDiffusion(\n",
    "    input_size = (2,), \n",
    "    noise_steps= noise_steps,\n",
    "    device=device,\n",
    "    beta_start=beta_start,\n",
    "    beta_end=beta_end,\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with single goal\n",
    "\n",
    "for iters in tqdm(range(goal_num * epochs)):    \n",
    "    goals = gen_goals(goal_bounds, goal_num)\n",
    "    expanded_goals = goals.unsqueeze(1).expand(-1, n, -1)\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    random_offsets = (torch.rand(*expanded_goals.shape, device=goals.device, dtype=goals.dtype) * 2 - 1.) * 0.1\n",
    "    x0 = (expanded_goals + random_offsets).view(-1,2)\n",
    "    obs = overlay_image(bg, img_size, wastes, x0)\n",
    "    t = diffusion.sample_timesteps(batch_size).to(device)\n",
    "    \n",
    "    x_noisy, noise = diffusion.forward_diffusion(x0, t)\n",
    "    noise_pred = model(obs, x_noisy, t)\n",
    "    loss =  F.l1_loss(noise, noise_pred)\n",
    "#     loss = F.mse_loss(noise, noise_pred)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if iters % 500 == 0:\n",
    "        print(f\"iter {iters}: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with single + multiple goals\n",
    "\n",
    "train_goal_num = goal_num * (2**(goal_num - 1)) # if 3 goals: 12\n",
    "train_goals = [len(list(itertools.combinations([i for i in range(goal_num)], i+1))* (i+1)) \\\n",
    "               for i in range(goal_num)] # if 3 goals: [3, 6, 3]\n",
    "train_comb = [len(list(itertools.combinations([i for i in range(goal_num)], i+1))) \\\n",
    "              for i in range(goal_num)] # just a list of combinations of goal num. if 3: [3, 3, 1]\n",
    "\n",
    "assert batch_size % train_goal_num == 0, 'batch size has to be divided by the goal number'\n",
    "n = batch_size // train_goal_num  # if 3 goals: batch -> n * 12 \n",
    "\n",
    "for iters in tqdm(range(train_goal_num * epochs)):\n",
    "    gs = random.randrange(goal_num)        \n",
    "    goals = gen_goals(goal_bounds, train_goal_num)\n",
    "    \n",
    "    expanded_goals = goals.unsqueeze(1).expand(-1, n, -1)\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    random_offsets = (torch.rand(*expanded_goals.shape, device=goals.device, dtype=goals.dtype) * 2 - 1.) * 0.1\n",
    "    goal_pos = (expanded_goals + random_offsets).view(-1,2)\n",
    "    obs = []\n",
    "    st = 0\n",
    "    for i, t in enumerate(train_goals):\n",
    "        if i == 0: \n",
    "            obs.append(overlay_image(bg, img_size, wastes, goal_pos[st:st + n * t]))\n",
    "        else:\n",
    "            obs.append(overlay_images(bg, img_size, wastes, goal_pos[st:st + n * t], i+1))\n",
    "        st = st + n * t\n",
    "    x0 = goal_pos.unsqueeze(1)\n",
    "    obs = torch.cat(obs, dim=0)\n",
    "    \n",
    "    # duplicate obs to match the size with x0\n",
    "    duplicates = []\n",
    "    for i, tr in enumerate(train_comb):\n",
    "        if i > 0: \n",
    "            duplicates.append(obs[n*prev_tr:n*(prev_tr + tr)].repeat(i,1,1,1))\n",
    "            tr = prev_tr + tr\n",
    "        prev_tr = tr\n",
    "\n",
    "    # TODO: Below new_obs is only capable when the goal number is 3.\n",
    "    comb_sum = [0] + [n*(train_comb[c]+train_comb[c+1]) for c in range(len(train_comb)-1)]\n",
    "    new_obs = torch.cat([obs[comb_sum[n//2]:comb_sum[n//2+1]] if n%2 == 0 else duplicates[n-1] \\\n",
    "                         for n in range(len(comb_sum)-1)*2], dim=0)\n",
    "#     new_obs = torch.cat([\n",
    "#         obs[:n*(train_comb[0]+train_comb[1])],\n",
    "#         duplicates[0],\n",
    "#         obs[n*(train_comb[0]+train_comb[1]):n*(train_comb[0]+train_comb[1]+train_comb[2])],\n",
    "#         duplicates[1],\n",
    "#         obs[14:]\n",
    "#     ], dim=0)\n",
    "        \n",
    "    t = diffusion.sample_timesteps(batch_size).to(device)\n",
    "    \n",
    "    x_noisy, noise = diffusion.forward_diffusion(x0, t)\n",
    "    noise_pred = model(new_obs, x_noisy, t)\n",
    "    loss =  F.l1_loss(noise, noise_pred)\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if iters % (epochs//10) == 0:\n",
    "        print(f\"iter {iters}: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scorefield.utils.utils import log_num_check, get_url_pretrained\n",
    "\n",
    "model_pth = f\"./logs/pretrained/diverse_goalpos_{noise_steps}_{beta_start}~{beta_end}.pt\"\n",
    "model_pth = log_num_check(model_pth)\n",
    "torch.save(model.state_dict(), model_pth)\n",
    "\n",
    "# url = 'https://drive.google.com/uc?export=download&id=1CtqczM5cry7wg4poiCv_UeKfIrLtrx9V'\n",
    "# get_url_pretrained(url, 'model.pt')\n",
    "# model.load_state_dict(torch.load(f'model.pt'))\n",
    "# model.load_state_dict(torch.load(f'./logs/pretrained/diverse_goalpos_{noise_steps}_{beta_start}~{beta_end}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_samples=1000\n",
    "new_goals = gen_goals([-.8,.8,-.8,.8], goal_num)       # (1, goal_num, 2)\n",
    "obs_T = overlay_image(bg, img_size, wastes, new_goals) # (goal_num, 3, H, W)\n",
    "\n",
    "c = 10\n",
    "fig,axs = plt.subplots(goal_num, c + 1, figsize=(20,20))\n",
    "T = diffusion.noise_steps\n",
    "step_size = int(T / c)\n",
    "dot_size = 2\n",
    "\n",
    "model.eval()\n",
    "# x_trace = []\n",
    "ims = []\n",
    "with torch.no_grad():\n",
    "    # x_T = torch.tensor([[0., 0.]], device=device, dtype=torch.float32)\n",
    "    x_T = gen_goals(agent_bounds, n=(goal_num, eval_samples))\n",
    "    x = x_T    # (eval_samples, 2)\n",
    "\n",
    "    for i in tqdm(reversed(range(1, noise_steps)), position=0):\n",
    "        bkg = bg.copy()\n",
    "        im = overlay_goal_agent(bkg, wastes, new_goals.cpu(), x.cpu(), dot_size)\n",
    "        ims.append(im)\n",
    "#         x_trace.append(x)\n",
    "\n",
    "        if (T-1-i) % step_size == 0:\n",
    "            k = (T-1-i) // step_size\n",
    "            backg = bg.copy()\n",
    "            img_sample = overlay_goal_agent(backg, wastes, new_goals.cpu(), x.cpu(), dot_size)\n",
    "            for s in range(len(img_sample)):\n",
    "                axs[s,k].imshow(img_sample[s])\n",
    "                axs[0,k].set_title(f't = {T-1-i}')\n",
    "                axs[s,k].axis('off')\n",
    "\n",
    "        t = (torch.ones(1) * i).long().to(device)\n",
    "        while True:\n",
    "            predicted_noise = model(obs_T, x, t)\n",
    "\n",
    "            alpha = diffusion.alpha[t]\n",
    "            alpha_hat = diffusion.alpha_hat[t]\n",
    "            beta = diffusion.beta[t]\n",
    "            if i > 1:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = torch.zeros_like(x)\n",
    "\n",
    "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) \\\n",
    "                        * predicted_noise) + torch.sqrt(beta) * noise\n",
    "            mask = (x.abs() > 1)\n",
    "            x[mask] = torch.clamp(x[mask], min=-.9, max=.9)\n",
    "            if (x.abs() <=1).all():\n",
    "                break\n",
    "\n",
    "    backg = bg.copy()\n",
    "    img_sample = overlay_goal_agent(backg, wastes, new_goals.cpu(),x.cpu(), dot_size)\n",
    "    for s in range(len(img_sample)):\n",
    "        axs[s,-1].imshow(img_sample[s])\n",
    "        axs[0,-1].set_title(f't = {T}')\n",
    "        axs[s,-1].axis('off')\n",
    "\n",
    "    bkg = bg.copy()\n",
    "    im = overlay_goal_agent(bkg, wastes, new_goals.cpu(), x.cpu(), dot_size)       \n",
    "    ims.append(im)\n",
    "#     x_trace.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/new_goal_video/img_list1.npy', ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 10\n",
    "fig,axs = plt.subplots(1, c + 1, figsize=(20,20))\n",
    "axs = axs.flatten()\n",
    "T = diffusion.noise_steps\n",
    "step_size = int(T / c)\n",
    "dot_size = 2\n",
    "\n",
    "goals = gen_goals(goal_bounds, goal_num)\n",
    "\n",
    "objs = wastes.copy()\n",
    "gs = goals.clone()\n",
    "\n",
    "obs_T = overlay_images(bg, img_size, objs, gs)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # x_T = torch.tensor([[0.5, 0.5]], device=device, dtype=torch.float32)\n",
    "    x_T = gen_goals(agent_bounds, n=(1, eval_samples)).unsqueeze(0)\n",
    "    x = x_T\n",
    "    \n",
    "    imgs=[]\n",
    "    for i in tqdm(reversed(range(1, noise_steps)), position=0):\n",
    "        if (T-1-i) % step_size == 0:\n",
    "            k = (T-1-i) // step_size\n",
    "            img_sample = overlay_goals_agent(bg, objs, gs.cpu(), x.cpu(), dot_size)\n",
    "            axs[k].imshow(img_sample)\n",
    "            axs[k].set_title(f't = {T-1-i}')\n",
    "            axs[k].axis('off')\n",
    "            imgs.append(img_sample)\n",
    "\n",
    "        t = (torch.ones(1) * i).long().to(device)\n",
    "        while True:\n",
    "            predicted_noise = model(obs_T, x, t)\n",
    "            alpha = diffusion.alpha[t]\n",
    "            alpha_hat = diffusion.alpha_hat[t]\n",
    "            beta = diffusion.beta[t]\n",
    "            if i > 1:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = torch.zeros_like(x)\n",
    "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) \\\n",
    "                        * predicted_noise) + torch.sqrt(beta) * noise\n",
    "            # if (abs(x[0][0]) <= 1.) & (abs(x[0][1]) <= 1.):\n",
    "            #     break\n",
    "            mask = (x.abs() > 1)\n",
    "            x[mask] = torch.clamp(x[mask], min=-.9, max=.9)\n",
    "            if (x.abs() <=1).all():\n",
    "                break\n",
    "\n",
    "#         exclude_idx = -1\n",
    "#         for i in range(len(gs)):\n",
    "#             if get_distance(x[0], gs[i]) < 0.1 and len(gs) > 1:\n",
    "#                 exclude_idx = i\n",
    "#                 break\n",
    "#         if exclude_idx > -1:\n",
    "#             objs = objs[:i] + objs[i+1:]\n",
    "#             gs = torch.cat([gs[:i], gs[i+1:]], dim=0)\n",
    "#             obs_T = overlay_images(bg, img_size, objs, gs)\n",
    "\n",
    "    img_sample = overlay_goals_agent(bg, objs, gs.cpu(),x.cpu(), dot_size)\n",
    "    axs[-1].imshow(img_sample)\n",
    "    axs[-1].set_title(f't = {T}')\n",
    "    axs[-1].axis('off')\n",
    "    imgs.append(img_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/new_goals_video/img_list.npy', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
