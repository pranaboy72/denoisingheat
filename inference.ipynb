{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from scorefield.models.ddpm.denoising_diffusion import Unet\n",
    "from scorefield.models.heat.heat_diffusion import HeatDiffusion, HeatDiffusion_Revised\n",
    "from scorefield.utils.rl_utils import load_config\n",
    "from scorefield.utils.utils import (\n",
    "    gen_goals, overlay_goal, overlay_multiple, combine_objects, overlay_images,\n",
    "    overlay_goal_agent, overlay_goals_agent, log_num_check,\n",
    "    draw_obstacles_pil, convert_to_obstacle_masks,\n",
    "    randgen_obstacle_masks, draw_obstacles_pixel,\n",
    "    vector_field, clip_vectors\n",
    ")\n",
    "from scorefield.utils.diffusion_utils import bilinear_interpolate, bilinear_interpolate_samples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from typing import Optional\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Args\n",
    "config_dir = \"./scorefield/configs/heat_diffusion.yaml\"\n",
    "args = load_config(config_dir)\n",
    "device = args['device']\n",
    "\n",
    "bg = Image.open('assets/toy_exp/background0.png')\n",
    "wastes = []\n",
    "wastes.append(Image.open('assets/toy_exp/waste0.png'))\n",
    "# wastes.append(Image.open('assets/toy_exp/waste4.png'))\n",
    "# wastes.append(Image.open('assets/toy_exp/waste5.png'))\n",
    "\n",
    "\n",
    "img_size = args['image_size']\n",
    "goal_bounds = args['goal_bounds']\n",
    "goal_num = len(wastes)\n",
    "agent_bounds = args['agent_bounds']\n",
    "obstacle_pos = args['obstacles']\n",
    "\n",
    "model_path = os.path.join(args['log_path'], args['model_path'])\n",
    "\n",
    "u0 = args['u0']\n",
    "min_heat_step = args['min_heat_step']\n",
    "max_heat_step = args['max_heat_step']\n",
    "noise_steps = args['noise_steps']\n",
    "sample_num = args['sample_num']\n",
    "time_type = args['time_type']\n",
    "\n",
    "epochs = args['epochs']\n",
    "train_lr = args['train_lr']\n",
    "batch_size = noise_steps #args['batch_size']\n",
    "\n",
    "class Unet2D(Unet):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim, \n",
    "        out_dim, \n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "    ):\n",
    "        super().__init__(dim=dim, out_dim=out_dim, dim_mults=dim_mults)\n",
    "\n",
    "    def forward(self, obs, t, x_t:Optional[torch.Tensor]=None):\n",
    "        score_map = super().forward(obs, t)\n",
    "        if x_t is not None:\n",
    "            score = bilinear_interpolate_samples(score_map, x_t)    # output: (B,2)\n",
    "            return score, score_map.permute(0,2,3,1)\n",
    "        else:\n",
    "            return score_map.permute(0, 2, 3, 1)\n",
    "    \n",
    "model = Unet2D(\n",
    "    dim=img_size,\n",
    "    out_dim = 2,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    ").to(device)\n",
    "\n",
    "diffusion = HeatDiffusion_Revised(\n",
    "    image_size=img_size,\n",
    "    u0 = u0,\n",
    "    noise_steps=noise_steps,\n",
    "    min_heat_step=min_heat_step,\n",
    "    max_heat_step=max_heat_step,\n",
    "    time_type=time_type,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'./runs/Sep09_13-07-05_workspace-ryae9dru7a3u-0/model_params.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation pre-setting\n",
    "\n",
    "# background = draw_obstacles_pil(bg, obstacle_pos)\n",
    "# obstacle_masks = convert_to_obstacle_masks(noise_steps, background[0].size, img_size, obstacle_pos)\n",
    "obstacle_masks = randgen_obstacle_masks(1, img_size)\n",
    "background = draw_obstacles_pixel(bg, obstacle_masks)\n",
    "\n",
    "obstacle_masks = obstacle_masks[0].unsqueeze(0)\n",
    "goals = torch.tensor([[[-0.7, 0]]], device=device, dtype=torch.float32)\n",
    "obs_T = overlay_goal(background, img_size, wastes, goals)\n",
    "\n",
    "plt.imshow(obs_T[0].permute(1,2,0).cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation - Single goal\n",
    "\n",
    "lan_t = 200  # 4\n",
    "epsilon = .01\n",
    "\n",
    "background = draw_obstacles_pil(bg, obstacle_pos)\n",
    "obstacle_masks = convert_to_obstacle_masks(noise_steps, background[0].size, img_size, obstacle_pos)\n",
    "# bg = gen_obstacles(bg, obstacle_pos)\n",
    "# new_goals = torch.tensor([[[-0.7, -0.7]]]*goal_num, device=device, dtype=torch.float32)\n",
    "# obs_T = overlay_goal(bg, img_size, wastes, new_goals) # (goal_num, 3, H, W)\n",
    "\n",
    "# goals = gen_goals(goal_bounds, 1, img_size, obstacles=obstacle_masks)  \n",
    "# goals = torch.tensor([[[0.7, -0.7]]], device=device, dtype=torch.float32)\n",
    "# obs_T = overlay_goal(background, img_size, wastes, goals)\n",
    "\n",
    "obstacle_masks = obstacle_masks[0].unsqueeze(0)\n",
    "goals = torch.tensor([[[-0., -0.]]], device=device, dtype=torch.float32)\n",
    "obs_T = overlay_goal(background, img_size, wastes, goals)\n",
    "\n",
    "\n",
    "c = 10\n",
    "fig,axs = plt.subplots(goal_num, c, figsize=(20,20))\n",
    "\n",
    "T = diffusion.noise_steps\n",
    "step_size = int(T / c)\n",
    "dot_size = 3\n",
    "\n",
    "\n",
    "model.eval()\n",
    "ims = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_T = torch.tensor([[[0.7, 0.]]], device=device, dtype=torch.float32)\n",
    "    # x_T = gen_goals(agent_bounds, n=(goal_num, 1))\n",
    "    x = x_T\n",
    "    \n",
    "    for i in tqdm(reversed(range(1, T+1)), position=0):\n",
    "#         bkg = bg.copy()\n",
    "\n",
    "        if (T-i) % step_size == 0:\n",
    "            k = (T-i) // step_size\n",
    "            backg = background.copy()\n",
    "            img_sample = overlay_goal_agent(backg[0], wastes, goals.cpu(), x.cpu(), dot_size)\n",
    "            for s in range(len(img_sample)):\n",
    "                if len(img_sample) == 1:\n",
    "                    axs[k].imshow(img_sample[s])\n",
    "                    axs[k].set_title(f't = {T-i+1}')\n",
    "                    axs[k].axis('off')    \n",
    "                else:\n",
    "                    axs[s,k].imshow(img_sample[s])\n",
    "                    axs[0,k].set_title(f't = {T-i+1}')\n",
    "                    axs[s,k].axis('off')\n",
    "\n",
    "        t = (torch.ones(1) * i).long().to(device)\n",
    "\n",
    "        alpha = epsilon / diffusion.std[i-1] * (img_size/2)\n",
    "        \n",
    "        for _ in range(lan_t):\n",
    "            x_prev = x.clone()\n",
    "            score, _ = model(obs_T, t, x)\n",
    "            \n",
    "            x = x_prev + (alpha * score)/2 + (torch.randn_like(x) * torch.sqrt(alpha) * 0.05)\n",
    "\n",
    "            # if not ((x.abs() <=0.99) & (x[...,0].item() < obstacles_h[0]) & (x[...,0].item()>obstacles_h[1]) & \\\n",
    "            #     (x[...,1].item()<obstacles_w[0]) & (x[...,1].item()>obstacles_w[1])).all():\n",
    "            if not (x.abs() <=0.99).all():        \n",
    "                x = x_prev\n",
    "            bkg = background.copy()\n",
    "            im = overlay_goal_agent(bkg[0], wastes, goals.cpu(), x.cpu(), dot_size)\n",
    "            ims.append(im)\n",
    "\n",
    "    backg = background.copy()\n",
    "    img_sample = overlay_goal_agent(backg[0], wastes, goals.cpu(),x.cpu(), dot_size)\n",
    "    for s in range(len(img_sample)):\n",
    "        if len(img_sample) == 1:\n",
    "            axs[-1].imshow(img_sample[s])\n",
    "            axs[-1].set_title(f't = {T}')\n",
    "            axs[-1].axis('off')    \n",
    "        else:\n",
    "            axs[s,-1].imshow(img_sample[s])\n",
    "            axs[0,-1].set_title(f't = {T}')\n",
    "            axs[s,-1].axis('off')\n",
    "\n",
    "    bkg = background.copy()\n",
    "    im = overlay_goal_agent(bkg[0], wastes, goals.cpu(), x.cpu(), dot_size)       \n",
    "    ims.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/heat/eval.npy', ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the whole field\n",
    "\n",
    "i = 3\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y = np.linspace(-1, 1, img_size)\n",
    "x = np.linspace(-1, 1, img_size)\n",
    "xx, yy = np.meshgrid(x,y)\n",
    "coordinates = np.vstack((xx.ravel(), yy.ravel())).T\n",
    "coordinates = torch.tensor(coordinates).float().to(device)\n",
    "\n",
    "batch_size = 1024\n",
    "all_scores = []\n",
    "for j in tqdm(range(0, coordinates.size(0), batch_size)):\n",
    "    coords_batch = coordinates[j:j+batch_size]\n",
    "    \n",
    "    score_batch = []\n",
    "    for coord in coords_batch:\n",
    "        single_coord = coord.unsqueeze(0).unsqueeze(1)\n",
    "        with torch.no_grad():\n",
    "            score, _ = model(obs_T, (torch.ones(1) * i).long().to(device), single_coord)\n",
    "        score_batch.append(score.squeeze(1))\n",
    "        \n",
    "    all_scores.append(torch.stack(score_batch))\n",
    "scores = torch.cat(all_scores, dim=0)\n",
    "scores = scores.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the whole field\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "scores_x = scores[:, 1].reshape(img_size, img_size)\n",
    "scores_y = scores[:, 0].reshape(img_size, img_size)\n",
    "score_clip_x, score_clip_y = clip_vectors(scores_x, scores_y, 0.01)\n",
    "axes[0].quiver(xx, yy, score_clip_x.detach().cpu().numpy(), score_clip_y.detach().cpu().numpy(), angles='xy', scale_units='xy', scale=0.5)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlim(-1,1)\n",
    "axes[0].set_ylim(-1,1)\n",
    "\n",
    "# Ground truth\n",
    "obstacle_masks = convert_to_obstacle_masks(noise_steps, bg.size, img_size, obstacle_pos)\n",
    "background = draw_obstacles_pixel(bg, obstacle_masks)\n",
    "goal = torch.tensor([[[-0.7,-0.7]]]*noise_steps, device=device)\n",
    "obs = overlay_goal(background, img_size, wastes, goal)\n",
    "t = torch.tensor([i for i in range(1, noise_steps+1)], device=device)\n",
    "_, _, score_field, _ = diffusion.forward_diffusion(t, goal, sample_num, obstacle_masks)\n",
    "data = score_field[i]\n",
    "V = data[...,0]\n",
    "U = data[...,1]\n",
    "V_clip, U_clip = clip_vectors(V, U, 0.005)\n",
    "# V_clip, U_clip = V, U\n",
    "x, y = np.meshgrid(np.linspace(0, img_size-1, img_size), np.linspace(0,img_size-1,img_size))\n",
    "axes[1].quiver(x, y, U_clip.cpu().numpy(), V_clip.cpu().numpy(), angles='xy', scale_units='xy', scale=0.01)\n",
    "# axes[1].invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation - Multi goals\n",
    "\n",
    "c = 10\n",
    "fig,axs = plt.subplots(1, c + 1, figsize=(20,20))\n",
    "axs = axs.flatten()\n",
    "T = diffusion.noise_steps\n",
    "step_size = int(T / c)\n",
    "dot_size = 2\n",
    "\n",
    "goals = gen_goals(goal_bounds, goal_num)\n",
    "\n",
    "objs = wastes.copy()\n",
    "gs = goals.clone()\n",
    "\n",
    "obs_T = overlay_images(bg, img_size, objs, gs)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # x_T = torch.tensor([[0.5, 0.5]], device=device, dtype=torch.float32)\n",
    "    x_T = gen_goals(agent_bounds, n=(1, eval_samples)).unsqueeze(0)\n",
    "    x = x_T\n",
    "    \n",
    "    imgs=[]\n",
    "    for i in tqdm(reversed(range(1, noise_steps)), position=0):\n",
    "        if (T-1-i) % step_size == 0:\n",
    "            k = (T-1-i) // step_size\n",
    "            img_sample = overlay_goals_agent(bg, objs, gs.cpu(), x.cpu(), dot_size)\n",
    "            axs[k].imshow(img_sample)\n",
    "            axs[k].set_title(f't = {T-1-i}')\n",
    "            axs[k].axis('off')\n",
    "            imgs.append(img_sample)\n",
    "\n",
    "        t = (torch.ones(1) * i).long().to(device)\n",
    "        while True:\n",
    "            predicted_noise = model(obs_T, x, t)\n",
    "            alpha = diffusion.alpha[t]\n",
    "            alpha_hat = diffusion.alpha_hat[t]\n",
    "            beta = diffusion.beta[t]\n",
    "            if i > 1:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = torch.zeros_like(x)\n",
    "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) \\\n",
    "                        * predicted_noise) + torch.sqrt(beta) * noise\n",
    "            # if (abs(x[0][0]) <= 1.) & (abs(x[0][1]) <= 1.):\n",
    "            #     break\n",
    "            mask = (x.abs() > 1)\n",
    "            x[mask] = torch.clamp(x[mask], min=-.9, max=.9)\n",
    "            if (x.abs() <=1).all():\n",
    "                break\n",
    "\n",
    "#         exclude_idx = -1\n",
    "#         for i in range(len(gs)):\n",
    "#             if get_distance(x[0], gs[i]) < 0.1 and len(gs) > 1:\n",
    "#                 exclude_idx = i\n",
    "#                 break\n",
    "#         if exclude_idx > -1:\n",
    "#             objs = objs[:i] + objs[i+1:]\n",
    "#             gs = torch.cat([gs[:i], gs[i+1:]], dim=0)\n",
    "#             obs_T = overlay_images(bg, img_size, objs, gs)\n",
    "\n",
    "    img_sample = overlay_goals_agent(bg, objs, gs.cpu(),x.cpu(), dot_size)\n",
    "    axs[-1].imshow(img_sample)\n",
    "    axs[-1].set_title(f't = {T}')\n",
    "    axs[-1].axis('off')\n",
    "    imgs.append(img_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
