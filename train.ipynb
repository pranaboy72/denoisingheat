{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\toy2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from denoisingheat.models.ddpm.denoising_diffusion import Unet\n",
    "from denoisingheat.models.heat.heat_diffusion import HeatDiffusion_Revised\n",
    "from denoisingheat.utils.utils import (\n",
    "    gen_goals, overlay_goal, randgen_obstacle_masks, draw_obstacles_pixel, load_config\n",
    ")\n",
    "from denoisingheat.utils.diffusion_utils import bilinear_interpolate_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Args\n",
    "config_dir = \"./denoisingheat/configs/heat_diffusion.yaml\"\n",
    "args = load_config(config_dir)\n",
    "device = args['device']\n",
    "\n",
    "bg = Image.open('assets/toy_exp/background0.png')\n",
    "wastes = []\n",
    "wastes.append(Image.open('assets/toy_exp/waste0.png'))\n",
    "# wastes.append(Image.open('assets/toy_exp/waste4.png'))\n",
    "# wastes.append(Image.open('assets/toy_exp/waste5.png'))\n",
    "\n",
    "\n",
    "img_size = args['image_size']\n",
    "goal_bounds = args['goal_bounds']\n",
    "goal_num = len(wastes)\n",
    "agent_bounds = args['agent_bounds']\n",
    "obstacle_pos = args['obstacles']\n",
    "\n",
    "model_path = os.path.join(args['log_path'], args['model_path'])\n",
    "\n",
    "u0 = args['u0']\n",
    "min_heat_step = args['min_heat_step']\n",
    "max_heat_step = args['max_heat_step']\n",
    "noise_steps = args['noise_steps']\n",
    "sample_num = args['sample_num']\n",
    "time_type = args['time_type']\n",
    "\n",
    "iterations = args['iterations']\n",
    "train_lr = args['train_lr']\n",
    "batch_size = args['batch_size'] #args['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setups - Model & Heat-inspired diffusion kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet2D(Unet):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim, \n",
    "        out_dim, \n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "    ):\n",
    "        super().__init__(dim=dim, out_dim=out_dim, dim_mults=dim_mults)\n",
    "\n",
    "    def forward(self, obs, t, x_t:Optional[torch.Tensor]=None):\n",
    "        score_field = super().forward(obs, t)\n",
    "        if x_t is not None:\n",
    "            score = bilinear_interpolate_samples(score_field, x_t)\n",
    "            return score, score_field.permute(0,2,3,1)\n",
    "        else:\n",
    "            return score_field.permute(0, 2, 3, 1)\n",
    "    \n",
    "model = Unet2D(\n",
    "    dim=img_size,\n",
    "    out_dim = 2,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    ").to(device)\n",
    "\n",
    "diffusion = HeatDiffusion_Revised(\n",
    "    image_size=img_size,\n",
    "    u0 = u0,\n",
    "    noise_steps=noise_steps,\n",
    "    min_heat_step=min_heat_step,\n",
    "    max_heat_step=max_heat_step,\n",
    "    time_type=time_type,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=train_lr)\n",
    "\n",
    "# model.load_state_dict(torch.load(f'./runs/heat/model_params.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "1. In each iteration, generate obstacles and goals randomly. We train focusing on scenarios with a single goal as well as those involving two goals.\n",
    "2. Train the model using our heat-inpsired diffusion kernel, ensuring to non-dimensionalize the score throughout training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with random single goal\n",
    "current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "log_dir = os.path.join('./runs/heat/', current_time)\n",
    "writer = SummaryWriter(log_dir)\n",
    "shutil.copy('./denoisingheat/configs/heat_diffusion.yaml', writer.log_dir)\n",
    "\n",
    "for iters in tqdm(range(iterations)):\n",
    "    # 1. Generate obstacles and goals randomly\n",
    "    obstacle_masks = randgen_obstacle_masks(batch_size, img_size)\n",
    "    background = draw_obstacles_pixel(bg, obstacle_masks)\n",
    "    multi_goals = gen_goals(goal_bounds, (2,batch_size//2), img_size, obstacles=obstacle_masks[:batch_size//2])\n",
    "    multi_goal = (torch.rand(batch_size//2, 2, 2, device=device, dtype=torch.float32) * 0.2 - 0.1) * 0.05 + multi_goals\n",
    "    single_goals = gen_goals(goal_bounds, batch_size//2, img_size, obstacles=obstacle_masks[batch_size//2:])\n",
    "    single_goal = (torch.rand(batch_size//2, 1, 2, device=device, dtype=torch.float32) * 0.2 - 0.1) * 0.05 + single_goals\n",
    "    obs1 = overlay_goal(background[:batch_size//2], img_size, wastes, multi_goal)\n",
    "    obs2 = overlay_goal(background[batch_size//2:], img_size, wastes, single_goal)\n",
    "    obs = torch.cat((obs1, obs2), dim=0)\n",
    "    goal = torch.cat((multi_goal[:,0].unsqueeze(1), single_goal), dim=0)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "\n",
    "    losses = []\n",
    "    target_scores = []\n",
    "    pred_scores = []\n",
    "    \n",
    "    # 2 Train the model\n",
    "    for i in range(1, noise_steps+1):\n",
    "        t = (torch.ones(1) * i).long().to(device)\n",
    "        with torch.no_grad():\n",
    "            _, score, _, x_t = diffusion.forward_diffusion(t.repeat(batch_size), goal, sample_num, obstacle_masks)\n",
    "        pred_score, _ = model(obs, t, x_t)\n",
    "        target_score = score * diffusion.std[i-1]\n",
    "\n",
    "        squared_diff = torch.sum((pred_score - target_score)**2, dim=-1)\n",
    "\n",
    "        losses.append(torch.mean(squared_diff))\n",
    "        target_scores.append(target_score)\n",
    "        pred_scores.append(pred_score)\n",
    "    \n",
    "    loss = sum(losses)/len(losses)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    target_scores = torch.stack(target_scores)\n",
    "    pred_scores = torch.stack(pred_scores)\n",
    "\n",
    "    target_score_norm = torch.norm(target_scores.detach(), dim=-1)\n",
    "    pred_score_norm = torch.norm(pred_scores.detach(), dim=-1)\n",
    "\n",
    "    dotprod = torch.sum(target_scores.detach() * pred_scores.detach(), dim=-1)\n",
    "    cosine_sim = dotprod / (torch.norm(target_scores.detach(), dim=-1) * torch.norm(pred_scores.detach(), dim=-1)+1e-8)\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", loss.item(), iters)\n",
    "    writer.add_scalar(\"Norm/target_score\", torch.mean(target_score_norm).item(), iters)\n",
    "    writer.add_scalar(\"Norm/pred_score\", torch.mean(pred_score_norm).item(), iters)\n",
    "    writer.add_scalar(\"Similarity/dot_product\", torch.mean(dotprod).item(), iters)\n",
    "    writer.add_scalar(\"Similarity/cosine_similarity\", torch.mean(cosine_sim).item(), iters)\n",
    "        \n",
    "    if iters == iterations // 2:\n",
    "        torch.save(model.state_dict(), os.path.join(writer.log_dir, 'model_params_half.pt'))\n",
    "    elif iters == int(iterations*3/4):\n",
    "        torch.save(model.state_dict(), os.path.join(writer.log_dir, 'model_params_half.pt'))\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(writer.log_dir, 'model_params.pt'))\n",
    "            \n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
